{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative Adversarial Networks（GAN）\n",
    "============================================\n",
    "\n",
    "Before ( Intuition Philosophy motivation)\n",
    "--------------\n",
    "> ### “What I cannot create, I do not understand.”  \n",
    ">                                           — Richard Feynman\n",
    "\n",
    "The trick is that the neural networks we use as generative models have a number of parameters significantly smaller than the amount of data we train them on, so the models are forced to discover and efficiently internalize the essence of the data in order to generate it.\n",
    "\n",
    "***\n",
    "### * main idea\n",
    "comes from:  \n",
    "**Game Theory**: zero-sum two-person game / **nash equilibrium**\n",
    "\n",
    "discriminator **VS** generator  \n",
    "\n",
    "> These two networks are therefore locked in a battle: the **discriminator(D)** is trying to distinguish real images from fake images and the **generator(G)** is trying to create images that make the discriminator think they are real. In the end, the generator network is outputting images that are indistinguishable from real images for the discriminator.  \n",
    "\n",
    "![GAN](https://blog.slinuxer.com/wp-content/uploads/2016/10/gan.jpg)\n",
    "\n",
    "\n",
    "### * Minimax objective function\n",
    "> $$ \\min_{G}\\max_{D}V(D,E)\\ =\\ E_{x\\sim p_{Data}(x)}[logD(x)]+E_{z\\sim p_z(z)}[log(1-D(G(z)))] $$\n",
    "\n",
    "![gt](http://upload-images.jianshu.io/upload_images/743541-92c379ef810d5db1.png?imageMogr2/auto-orient/strip%7CimageView2/2)\n",
    "\n",
    "### * Pros and Cons\n",
    "Pros:\n",
    "> can produce state of the art log-likelihood estimates and realistic samples. (demonstrated in [[GAN]](https://arxiv.org/pdf/1406.2661v1.pdf))  \n",
    "> Markov chains are never needed, only backpropagation is used to obtain gradients, no inference is required during learning  \n",
    "\n",
    "Cons:\n",
    "> too free. hard to control.   \n",
    "> hard to converge.  \n",
    "\n",
    "### * Evolutions\n",
    "**GAN**  2014 [[paper]](https://arxiv.org/pdf/1406.2661v1.pdf)  \n",
    "the beginning. hard to converge.  \n",
    "\n",
    "**CGAN** 2014 [[paper]](https://arxiv.org/pdf/1411.1784v1.pdf)  \n",
    "> $$ \\min_{G}\\max_{D}V(D,E)\\ =\\ E_{x\\sim p_{Data}(x)}[logD(x\\mid y)]+E_{z\\sim p_z(z)}[log(1-D(G(z\\mid y)))] $$\n",
    "![CGAN](images/CGAN.png)  \n",
    "\n",
    "**LAPGAN** 2015 [[paper]](https://arxiv.org/pdf/1506.05751v1.pdf)\n",
    "\n",
    "\n",
    "**! DCGAN** [[paper]](https://arxiv.org/pdf/1511.06434v2.pdf) [[github]](https://github.com/Newmu/dcgan_code)\n",
    "\n",
    "\n",
    "### * Applications\n",
    "\n",
    "* Arithmetic on faces  \n",
    "![arithmetic](https://raw.githubusercontent.com/Newmu/dcgan_code/master/images/faces_arithmetic_collage.png)\n",
    "\n",
    "* Rotations are linear in latent space\n",
    "![rotations](https://raw.githubusercontent.com/Newmu/dcgan_code/master/images/turn_vector.png)\n",
    "\n",
    "\n",
    "#### Other apps using GAN:  \n",
    "Image Completion with Deep Learning in TensorFlow [[blog]](http://bamos.github.io/2016/08/09/deep-completion/#introduction)  \n",
    "\n",
    "http://bamos.github.io/2016/08/09/deep-completion/#step-1-interpreting-images-as-samples-from-a-probability-distribution"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
